{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c238dfe02b23408e8f4a08a8a916ddb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b93d94a1517644e8be84b9075aa687a9",
              "IPY_MODEL_43bf30bd665248498138a90ee8c90a9a"
            ],
            "layout": "IPY_MODEL_aadc5270699045fbb2fb7dd3964372f6"
          }
        },
        "b93d94a1517644e8be84b9075aa687a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "x",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4a76da6a43d7488580647c97687036ad",
            "max": 10,
            "min": 1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_f3a58ea65709434d869a9038440d4011",
            "value": 8
          }
        },
        "43bf30bd665248498138a90ee8c90a9a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5f8ae356a747478e828e7a99888f5b15",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "64"
                },
                "metadata": {}
              }
            ]
          }
        },
        "aadc5270699045fbb2fb7dd3964372f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a76da6a43d7488580647c97687036ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a58ea65709434d869a9038440d4011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "5f8ae356a747478e828e7a99888f5b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Parte secreta que faz o cﾃｳdigo funcionar 洵ｰ"
      ],
      "metadata": {
        "id": "evEX-cy2yTf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n"
      ],
      "metadata": {
        "id": "2Tc-WkaceiHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684b8f5f-601e-493a-bd43-0f6dd469433d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.35.81-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.81 (from boto3)\n",
            "  Downloading botocore-1.35.81-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.81->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.81->boto3) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.81->boto3) (1.17.0)\n",
            "Downloading boto3-1.35.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.81-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.81 botocore-1.35.81 jmespath-1.0.1 s3transfer-0.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "aws_access_key=\"XXXXXXXXXXXXXXXX\" #Trocar pela sua prﾃｳpria access key!! Nﾃ｣o esquecer!!\n",
        "aws_secret_key=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" #Trocar pela sua prﾃｳpria access key!! Nﾃ｣o esquecer!!\n",
        "region=\"us-east-1\"\n",
        "\n",
        "s3 = boto3.client('s3', aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)\n",
        "rekognition = boto3.client(\n",
        "    'rekognition',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=\"us-east-1\"\n",
        ")\n",
        "\n",
        "comprehend = boto3.client(\n",
        "    'comprehend',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=region\n",
        ")\n",
        "\n",
        "polly = boto3.client(\n",
        "    'polly',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=region\n",
        ")\n",
        "\n",
        "lex = boto3.client(\n",
        "    'lexv2-runtime',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=region\n",
        ")"
      ],
      "metadata": {
        "id": "jM-uic6Hyj_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cﾃｳdigo AWS Comprehend 汨"
      ],
      "metadata": {
        "id": "m4ZuqVh5y23c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    response = comprehend.detect_sentiment(Text=text, LanguageCode='pt')\n",
        "    print(\"Anﾃ｡lise de Sentimento:\")\n",
        "    print(f\"Sentimento principal: {response['Sentiment']}\")\n",
        "    print(\"Pontuaﾃｧﾃｵes:\")\n",
        "    for sentiment, score in response['SentimentScore'].items():\n",
        "        print(f\"  {sentiment}: {score:.2f}\")\n",
        "\n",
        "# Exemplo de texto\n",
        "text = \"Faaala, povo!! Sou o Pedro Guth e como um engenheiro entusiastaﾂ em dados e IA minha jornada profissional inclui experiﾃｪncia na maior empresa de consultoria em tecnologias de nuvem, enriquecida por estudos em ML em grandes universidades. Meu foco atual estﾃ｡ na criaﾃｧﾃ｣o de exames prﾃ｡ticos que refletem os desafios e complexidades de cenﾃ｡rios do mundo real. Esses exames sﾃ｣o ajustados para testar e aprimorar sua compreensﾃ｣o, preparando vocﾃｪ para as nuances da nuvem, dos dados e dos domﾃｭnios de IA. Se vocﾃｪ deseja dominar essas ﾃ｡reas e obter a certificaﾃｧﾃ｣o, estou aqui para orientﾃ｡-lo a atingi-las com seguranﾃｧa.\"\n",
        "analyze_sentiment(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA-BVtpJh53b",
        "outputId": "c2ced4db-39df-484f-92dd-7b6ede182b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anﾃ｡lise de Sentimento:\n",
            "Sentimento principal: NEUTRAL\n",
            "Pontuaﾃｧﾃｵes:\n",
            "  Positive: 0.29\n",
            "  Negative: 0.00\n",
            "  Neutral: 0.71\n",
            "  Mixed: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_key_phrases(text):\n",
        "    response = comprehend.detect_key_phrases(Text=text, LanguageCode='pt')\n",
        "    print(\"Frases-chave detectadas:\")\n",
        "    for phrase in response['KeyPhrases']:\n",
        "        print(f\"  Texto: {phrase['Text']}, Confianﾃｧa: {phrase['Score']:.2f}\")\n",
        "\n",
        "# Exemplo de texto\n",
        "text = \"Faaala, povo!! Sou o Pedro Guth e como um engenheiro entusiastaﾂ em dados e IA minha jornada profissional inclui experiﾃｪncia na maior empresa de consultoria em tecnologias de nuvem, enriquecida por estudos em ML em grandes universidades. Meu foco atual estﾃ｡ na criaﾃｧﾃ｣o de exames prﾃ｡ticos que refletem os desafios e complexidades de cenﾃ｡rios do mundo real. Esses exames sﾃ｣o ajustados para testar e aprimorar sua compreensﾃ｣o, preparando vocﾃｪ para as nuances da nuvem, dos dados e dos domﾃｭnios de IA. Se vocﾃｪ deseja dominar essas ﾃ｡reas e obter a certificaﾃｧﾃ｣o, estou aqui para orientﾃ｡-lo a atingi-las com seguranﾃｧa.\"\n",
        "detect_key_phrases(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EopphEQJuD9f",
        "outputId": "e7fe6a24-466b-4e9e-9e7b-7eb99d8c97ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frases-chave detectadas:\n",
            "  Texto: Faaala, Confianﾃｧa: 0.90\n",
            "  Texto: o Pedro Guth, Confianﾃｧa: 0.99\n",
            "  Texto: um engenheiro entusiastaﾂ em dados, Confianﾃｧa: 0.99\n",
            "  Texto: IA, Confianﾃｧa: 0.96\n",
            "  Texto: jornada profissional, Confianﾃｧa: 0.90\n",
            "  Texto: experiﾃｪncia na maior empresa de consultoria em tecnologias de nuvem, Confianﾃｧa: 0.99\n",
            "  Texto: estudos em ML, Confianﾃｧa: 0.85\n",
            "  Texto: grandes universidades, Confianﾃｧa: 0.93\n",
            "  Texto: foco atual, Confianﾃｧa: 1.00\n",
            "  Texto: criaﾃｧﾃ｣o de exames prﾃ｡ticos, Confianﾃｧa: 1.00\n",
            "  Texto: que, Confianﾃｧa: 1.00\n",
            "  Texto: os desafios e complexidades de cenﾃ｡rios do mundo real, Confianﾃｧa: 1.00\n",
            "  Texto: Esses exames, Confianﾃｧa: 1.00\n",
            "  Texto: compreensﾃ｣o, Confianﾃｧa: 0.59\n",
            "  Texto: vocﾃｪ, Confianﾃｧa: 1.00\n",
            "  Texto: as nuances da nuvem, Confianﾃｧa: 1.00\n",
            "  Texto: dados, Confianﾃｧa: 0.99\n",
            "  Texto: domﾃｭnios de IA, Confianﾃｧa: 1.00\n",
            "  Texto: vocﾃｪ, Confianﾃｧa: 1.00\n",
            "  Texto: essas ﾃ｡reas, Confianﾃｧa: 1.00\n",
            "  Texto: a certificaﾃｧﾃ｣o, Confianﾃｧa: 1.00\n",
            "  Texto: seguranﾃｧa, Confianﾃｧa: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_language(text):\n",
        "    response = comprehend.detect_dominant_language(Text=text)\n",
        "    print(\"Idiomas detectados:\")\n",
        "    for language in response['Languages']:\n",
        "        print(f\"  Cﾃｳdigo: {language['LanguageCode']}, Confianﾃｧa: {language['Score']:.2f}\")\n",
        "\n",
        "# Exemplo de texto\n",
        "text = \"Faaala, povo!! Sou o Pedro Guth e como um engenheiro entusiastaﾂ em dados e IA minha jornada profissional inclui experiﾃｪncia na maior empresa de consultoria em tecnologias de nuvem, enriquecida por estudos em ML em grandes universidades. Meu foco atual estﾃ｡ na criaﾃｧﾃ｣o de exames prﾃ｡ticos que refletem os desafios e complexidades de cenﾃ｡rios do mundo real. Esses exames sﾃ｣o ajustados para testar e aprimorar sua compreensﾃ｣o, preparando vocﾃｪ para as nuances da nuvem, dos dados e dos domﾃｭnios de IA. Se vocﾃｪ deseja dominar essas ﾃ｡reas e obter a certificaﾃｧﾃ｣o, estou aqui para orientﾃ｡-lo a atingi-las com seguranﾃｧa.\"\n",
        "detect_language(text)\n"
      ],
      "metadata": {
        "id": "PBPhaRkXtp7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3cb830-396e-4e9f-9524-7d2e28e677cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Idiomas detectados:\n",
            "  Cﾃｳdigo: pt, Confianﾃｧa: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cﾃｳdigo AWS Polly 沁､"
      ],
      "metadata": {
        "id": "u5uDb5XDyaNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def synthesize_speech(text, output_file=\"output.mp3\", voice=\"Joanna\"):\n",
        "    response = polly.synthesize_speech(\n",
        "        Text=text,\n",
        "        OutputFormat='mp3',\n",
        "        VoiceId=voice\n",
        "    )\n",
        "\n",
        "    # Salvar o ﾃ｡udio em um arquivo\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(response['AudioStream'].read())\n",
        "\n",
        "    print(f\"ﾃ「dio gerado: {output_file}\")\n",
        "\n",
        "# Exemplo de uso\n",
        "text = \"Hello, welcome to AWS Polly! This is a simple demonstration of text-to-speech.\"\n",
        "synthesize_speech(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsOIqkeTyn7Y",
        "outputId": "60569e2a-bb86-4a64-e04b-b7657c02ca02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ﾃ「dio gerado: output.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"output.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8hlh1yqeyz0a",
        "outputId": "eed14e97-006c-45f7-e094-a5d2d6b8b003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6faf872e-5e1a-4200-bdcf-69350debd165\", \"output.mp3\", 33273)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_voices():\n",
        "    response = polly.describe_voices()\n",
        "    print(\"Vozes disponﾃｭveis:\")\n",
        "    for voice in response['Voices']:\n",
        "        print(f\"Nome: {voice['Id']}, Gﾃｪnero: {voice['Gender']}, Idioma: {voice['LanguageName']}\")\n",
        "\n",
        "# Execute a funﾃｧﾃ｣o\n",
        "list_voices()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8t_DzzCy1t4",
        "outputId": "483c0a7a-f3a2-4789-8d81-c789e7b7da99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vozes disponﾃｭveis:\n",
            "Nome: Isabelle, Gﾃｪnero: Female, Idioma: Belgian French\n",
            "Nome: Danielle, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Gregory, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Burcu, Gﾃｪnero: Female, Idioma: Turkish\n",
            "Nome: Jitka, Gﾃｪnero: Female, Idioma: Czech\n",
            "Nome: Sabrina, Gﾃｪnero: Female, Idioma: Swiss Standard German\n",
            "Nome: Patrick, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Alba, Gﾃｪnero: Female, Idioma: Castilian Spanish\n",
            "Nome: Raul, Gﾃｪnero: Male, Idioma: Castilian Spanish\n",
            "Nome: Joanna, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Ruth, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Lupe, Gﾃｪnero: Female, Idioma: US Spanish\n",
            "Nome: Kevin, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Filiz, Gﾃｪnero: Female, Idioma: Turkish\n",
            "Nome: Elin, Gﾃｪnero: Female, Idioma: Swedish\n",
            "Nome: Astrid, Gﾃｪnero: Female, Idioma: Swedish\n",
            "Nome: Tatyana, Gﾃｪnero: Female, Idioma: Russian\n",
            "Nome: Maxim, Gﾃｪnero: Male, Idioma: Russian\n",
            "Nome: Carmen, Gﾃｪnero: Female, Idioma: Romanian\n",
            "Nome: Ines, Gﾃｪnero: Female, Idioma: Portuguese\n",
            "Nome: Cristiano, Gﾃｪnero: Male, Idioma: Portuguese\n",
            "Nome: Vitoria, Gﾃｪnero: Female, Idioma: Brazilian Portuguese\n",
            "Nome: Ricardo, Gﾃｪnero: Male, Idioma: Brazilian Portuguese\n",
            "Nome: Camila, Gﾃｪnero: Female, Idioma: Brazilian Portuguese\n",
            "Nome: Maja, Gﾃｪnero: Female, Idioma: Polish\n",
            "Nome: Jan, Gﾃｪnero: Male, Idioma: Polish\n",
            "Nome: Jacek, Gﾃｪnero: Male, Idioma: Polish\n",
            "Nome: Ewa, Gﾃｪnero: Female, Idioma: Polish\n",
            "Nome: Ola, Gﾃｪnero: Female, Idioma: Polish\n",
            "Nome: Lisa, Gﾃｪnero: Female, Idioma: Belgian Dutch\n",
            "Nome: Ruben, Gﾃｪnero: Male, Idioma: Dutch\n",
            "Nome: Lotte, Gﾃｪnero: Female, Idioma: Dutch\n",
            "Nome: Laura, Gﾃｪnero: Female, Idioma: Dutch\n",
            "Nome: Ida, Gﾃｪnero: Female, Idioma: Norwegian\n",
            "Nome: Liv, Gﾃｪnero: Female, Idioma: Norwegian\n",
            "Nome: Seoyeon, Gﾃｪnero: Female, Idioma: Korean\n",
            "Nome: Kazuha, Gﾃｪnero: Female, Idioma: Japanese\n",
            "Nome: Tomoko, Gﾃｪnero: Female, Idioma: Japanese\n",
            "Nome: Takumi, Gﾃｪnero: Male, Idioma: Japanese\n",
            "Nome: Mizuki, Gﾃｪnero: Female, Idioma: Japanese\n",
            "Nome: Bianca, Gﾃｪnero: Female, Idioma: Italian\n",
            "Nome: Giorgio, Gﾃｪnero: Male, Idioma: Italian\n",
            "Nome: Carla, Gﾃｪnero: Female, Idioma: Italian\n",
            "Nome: Karl, Gﾃｪnero: Male, Idioma: Icelandic\n",
            "Nome: Dora, Gﾃｪnero: Female, Idioma: Icelandic\n",
            "Nome: Mathieu, Gﾃｪnero: Male, Idioma: French\n",
            "Nome: Lea, Gﾃｪnero: Female, Idioma: French\n",
            "Nome: Celine, Gﾃｪnero: Female, Idioma: French\n",
            "Nome: Chantal, Gﾃｪnero: Female, Idioma: Canadian French\n",
            "Nome: Gabrielle, Gﾃｪnero: Female, Idioma: Canadian French\n",
            "Nome: Penelope, Gﾃｪnero: Female, Idioma: US Spanish\n",
            "Nome: Miguel, Gﾃｪnero: Male, Idioma: US Spanish\n",
            "Nome: Mia, Gﾃｪnero: Female, Idioma: Mexican Spanish\n",
            "Nome: Lucia, Gﾃｪnero: Female, Idioma: Castilian Spanish\n",
            "Nome: Enrique, Gﾃｪnero: Male, Idioma: Castilian Spanish\n",
            "Nome: Conchita, Gﾃｪnero: Female, Idioma: Castilian Spanish\n",
            "Nome: Geraint, Gﾃｪnero: Male, Idioma: Welsh English\n",
            "Nome: Salli, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Matthew, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Kimberly, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Kendra, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Justin, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Joey, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Ivy, Gﾃｪnero: Female, Idioma: US English\n",
            "Nome: Aria, Gﾃｪnero: Female, Idioma: New Zealand English\n",
            "Nome: Ayanda, Gﾃｪnero: Female, Idioma: South African English\n",
            "Nome: Raveena, Gﾃｪnero: Female, Idioma: Indian English\n",
            "Nome: Aditi, Gﾃｪnero: Female, Idioma: Indian English\n",
            "Nome: Emma, Gﾃｪnero: Female, Idioma: British English\n",
            "Nome: Brian, Gﾃｪnero: Male, Idioma: British English\n",
            "Nome: Amy, Gﾃｪnero: Female, Idioma: British English\n",
            "Nome: Russell, Gﾃｪnero: Male, Idioma: Australian English\n",
            "Nome: Nicole, Gﾃｪnero: Female, Idioma: Australian English\n",
            "Nome: Olivia, Gﾃｪnero: Female, Idioma: Australian English\n",
            "Nome: Vicki, Gﾃｪnero: Female, Idioma: German\n",
            "Nome: Marlene, Gﾃｪnero: Female, Idioma: German\n",
            "Nome: Hans, Gﾃｪnero: Male, Idioma: German\n",
            "Nome: Naja, Gﾃｪnero: Female, Idioma: Danish\n",
            "Nome: Mads, Gﾃｪnero: Male, Idioma: Danish\n",
            "Nome: Sofie, Gﾃｪnero: Female, Idioma: Danish\n",
            "Nome: Gwyneth, Gﾃｪnero: Female, Idioma: Welsh\n",
            "Nome: Zhiyu, Gﾃｪnero: Female, Idioma: Chinese Mandarin\n",
            "Nome: Zeina, Gﾃｪnero: Female, Idioma: Arabic\n",
            "Nome: Hala, Gﾃｪnero: Female, Idioma: Gulf Arabic\n",
            "Nome: Arlet, Gﾃｪnero: Female, Idioma: Catalan\n",
            "Nome: Hannah, Gﾃｪnero: Female, Idioma: Austrian German\n",
            "Nome: Stephen, Gﾃｪnero: Male, Idioma: US English\n",
            "Nome: Kajal, Gﾃｪnero: Female, Idioma: Indian English\n",
            "Nome: Hiujin, Gﾃｪnero: Female, Idioma: Cantonese\n",
            "Nome: Suvi, Gﾃｪnero: Female, Idioma: Finnish\n",
            "Nome: Niamh, Gﾃｪnero: Female, Idioma: Irish English\n",
            "Nome: Arthur, Gﾃｪnero: Male, Idioma: British English\n",
            "Nome: Daniel, Gﾃｪnero: Male, Idioma: German\n",
            "Nome: Liam, Gﾃｪnero: Male, Idioma: Canadian French\n",
            "Nome: Pedro, Gﾃｪnero: Male, Idioma: US Spanish\n",
            "Nome: Sergio, Gﾃｪnero: Male, Idioma: Castilian Spanish\n",
            "Nome: Andres, Gﾃｪnero: Male, Idioma: Mexican Spanish\n",
            "Nome: Remi, Gﾃｪnero: Male, Idioma: French\n",
            "Nome: Adriano, Gﾃｪnero: Male, Idioma: Italian\n",
            "Nome: Thiago, Gﾃｪnero: Male, Idioma: Brazilian Portuguese\n",
            "Nome: Zayd, Gﾃｪnero: Male, Idioma: Gulf Arabic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def synthesize_with_ssml(output_file=\"ssml_output.mp3\"):\n",
        "    ssml_text = \"\"\"\n",
        "    <speak>\n",
        "        Hello! <break time=\"1s\"/>\n",
        "        Welcome to <emphasis>Amazon Polly</emphasis>.\n",
        "        This is an example of SSML text-to-speech.\n",
        "    </speak>\n",
        "    \"\"\"\n",
        "    response = polly.synthesize_speech(\n",
        "        Text=ssml_text,\n",
        "        OutputFormat='mp3',\n",
        "        VoiceId='Joanna',\n",
        "        TextType='ssml'\n",
        "    )\n",
        "\n",
        "    # Salvar o ﾃ｡udio em um arquivo\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(response['AudioStream'].read())\n",
        "\n",
        "    print(f\"ﾃ「dio gerado: {output_file}\")\n",
        "\n",
        "# Execute a funﾃｧﾃ｣o\n",
        "synthesize_with_ssml()\n",
        "\n",
        "# Baixe o arquivo gerado\n",
        "files.download(\"ssml_output.mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "euyakMG_y3EJ",
        "outputId": "c77a75cc-ebcc-4ee8-fb8f-193e648715f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ﾃ「dio gerado: ssml_output.mp3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65213f73-dc55-4417-8f01-499ff448cdbc\", \"ssml_output.mp3\", 40639)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def synthesize_multilingual(text, language_voice, output_file=\"multilingual.mp3\"):\n",
        "    response = polly.synthesize_speech(\n",
        "        Text=text,\n",
        "        OutputFormat='mp3',\n",
        "        VoiceId=language_voice\n",
        "    )\n",
        "\n",
        "    # Salvar o ﾃ｡udio em um arquivo\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(response['AudioStream'].read())\n",
        "\n",
        "    print(f\"ﾃ「dio gerado: {output_file}\")\n",
        "\n",
        "# Exemplo: Texto em espanhol\n",
        "text_es = \"Hola, bienvenidos a Amazon Polly. Esta es una demostraciﾃｳn de texto a voz.\"\n",
        "synthesize_multilingual(text_es, \"Lucia\")\n",
        "files.download(\"multilingual.mp3\")\n"
      ],
      "metadata": {
        "id": "fQ6LqhbUy45E",
        "outputId": "0c9e63c5-4a26-44bc-c072-d8ffee701c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ﾃ「dio gerado: multilingual.mp3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d76974f0-0403-4456-8840-dcb447c31a8e\", \"multilingual.mp3\", 29981)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar um lexicon existente\n",
        "def list_lexicons():\n",
        "    response = polly.list_lexicons()\n",
        "    print(\"Lexicons disponﾃｭveis:\")\n",
        "    for lexicon in response['Lexicons']:\n",
        "        print(f\"Nome: {lexicon['Name']}\")\n",
        "\n",
        "list_lexicons()\n"
      ],
      "metadata": {
        "id": "qeSHamk8y6sI",
        "outputId": "25f35d6b-cbc5-4914-9559-f53f2b998810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexicons disponﾃｭveis:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AWS Rekognition"
      ],
      "metadata": {
        "id": "Lm2KrmsXycdd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhBm5EUL1Wk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AWX Lex"
      ],
      "metadata": {
        "id": "uLHK7Wij1Xuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot_id = \"EOT9PSGXZN\"\n",
        "alias_id = \"SEU_ALIAS_ID\"\n",
        "locale_id = \"pt_BR\"  # Idioma configurado no bot\n",
        "\n",
        "def send_message_to_bot(message):\n",
        "    response = lex.recognize_text(\n",
        "        botId=bot_id,\n",
        "        botAliasId=alias_id,\n",
        "        localeId=locale_id,\n",
        "        sessionId=\"demo-session\",  # Identificador ﾃｺnico para a sessﾃ｣o\n",
        "        text=message\n",
        "    )\n",
        "\n",
        "    print(\"Resposta do bot:\")\n",
        "    print(response['messages'][0]['content'])\n",
        "\n",
        "# Exemplo de interaﾃｧﾃ｣o\n",
        "user_message = \"Olﾃ｡!\"\n",
        "send_message_to_bot(user_message)\n"
      ],
      "metadata": {
        "id": "u6LydbEF1atB",
        "outputId": "e94d74cd-1d4a-40c3-d20a-52102b454923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationException",
          "evalue": "An error occurred (ValidationException) when calling the RecognizeText operation: INVALID_REQUEST - Invalid bot name or alias",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2cfc182afd11>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Exemplo de interaﾃｧﾃ｣o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0muser_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Olﾃ｡!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msend_message_to_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-2cfc182afd11>\u001b[0m in \u001b[0;36msend_message_to_bot\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend_message_to_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response = lex.recognize_text(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mbotId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbot_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbotAliasId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malias_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m                 )\n\u001b[1;32m    568\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1021\u001b[0m             )\n\u001b[1;32m   1022\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValidationException\u001b[0m: An error occurred (ValidationException) when calling the RecognizeText operation: INVALID_REQUEST - Invalid bot name or alias"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "def send_audio_to_bot(audio_file):\n",
        "    with open(audio_file, \"rb\") as file:\n",
        "        audio_data = file.read()\n",
        "\n",
        "    response = lex.recognize_audio(\n",
        "        botId=bot_id,\n",
        "        botAliasId=alias_id,\n",
        "        localeId=locale_id,\n",
        "        sessionId=\"demo-session\",\n",
        "        inputStream=audio_data,\n",
        "        contentType='audio/l16; rate=16000; channels=1'  # Configuraﾃｧﾃ｣o padrﾃ｣o para ﾃ｡udio\n",
        "    )\n",
        "\n",
        "    print(\"Resposta do bot:\")\n",
        "    print(response['messages'][0]['content'])\n",
        "\n",
        "# Exemplo: Substitua 'audio.wav' pelo caminho do arquivo de ﾃ｡udio\n",
        "audio_file = \"audio.wav\"\n",
        "send_audio_to_bot(audio_file)\n"
      ],
      "metadata": {
        "id": "JVEBH_-_1iCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar atributos da sessﾃ｣o\n",
        "def get_session_attributes():\n",
        "    response = lex.get_session(\n",
        "        botId=bot_id,\n",
        "        botAliasId=alias_id,\n",
        "        localeId=locale_id,\n",
        "        sessionId=\"demo-session\"\n",
        "    )\n",
        "    print(\"Atributos da sessﾃ｣o:\")\n",
        "    print(response.get(\"sessionState\", {}).get(\"sessionAttributes\", {}))\n",
        "\n",
        "# Exemplo\n",
        "get_session_attributes()\n"
      ],
      "metadata": {
        "id": "7TzQuWwG1jbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_bot():\n",
        "    print(\"Digite 'exit' para sair.\")\n",
        "    while True:\n",
        "        user_message = input(\"Vocﾃｪ: \")\n",
        "        if user_message.lower() == \"exit\":\n",
        "            print(\"Encerrando a conversa.\")\n",
        "            break\n",
        "        send_message_to_bot(user_message)\n",
        "\n",
        "# Execute o chat\n",
        "chat_with_bot()\n"
      ],
      "metadata": {
        "id": "ReSniiWt1k-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduﾃｧﾃ｣o ao NumPy\n",
        "Este ﾃｩ um exemplo para demonstrar como calcular a mﾃｩdia de uma lista de nﾃｺmeros usando a biblioteca NumPy.\n"
      ],
      "metadata": {
        "id": "HmJcpGQMeAIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Lista de nﾃｺmeros\n",
        "numeros = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Calculando a mﾃｩdia\n",
        "media = np.mean(numeros)\n",
        "print(f\"A mﾃｩdia dos nﾃｺmeros ﾃｩ: {media}\")"
      ],
      "metadata": {
        "id": "fIu-RrCMeCAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interact\n",
        "\n",
        "def calcular_quadrado(x):\n",
        "    return x**2\n",
        "\n",
        "interact(calcular_quadrado, x=(1, 10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "c238dfe02b23408e8f4a08a8a916ddb1",
            "b93d94a1517644e8be84b9075aa687a9",
            "43bf30bd665248498138a90ee8c90a9a",
            "aadc5270699045fbb2fb7dd3964372f6",
            "4a76da6a43d7488580647c97687036ad",
            "f3a58ea65709434d869a9038440d4011",
            "5f8ae356a747478e828e7a99888f5b15"
          ]
        },
        "id": "cQrAzwmUeEyW",
        "outputId": "e54b02bb-3cf2-4e58-a57a-847075fa255e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=5, description='x', max=10, min=1), Output()), _dom_classes=('widget-int窶ｦ"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c238dfe02b23408e8f4a08a8a916ddb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.calcular_quadrado(x)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>calcular_quadrado</b><br/>def calcular_quadrado(x)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-1-fb5485ee1d05&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}